optimizer:
  name: adam
  lr: 5.e-3
  weight_decay: 1.e-6

train:
  epoch: 30
  batch_size: 8192 #4096 #512
  test_step: 1 # evaluate per {test_step} epochs
  reproducible: true
  seed: 2023
  save_model: true
  trainer: maerec_trainer
  log_loss: false
  tensorboard: true
  early_stop: true
  patience: 3
  workers: 0

test:
  metrics: [ndcg, recall] # choose in {ndcg, recall, precision, mrr}
  k: [5, 10, 20] # top-k
  batch_size: 8192 #512 # How many users per batch during validation
  workers: 0

data:
  type: sequential # choose in {general_cf, multi_behavior, sequential, social}
  name: gsshop # ml-20m
  seq_aug: true

model:
  name: maerec # case-insensitive
  con_batch: 2048
  max_seq_len: 30
  num_reco_neg: 40
  reg: 1.e-6 # 1e-8
  ssl_reg: 1.e-2 # 1e-3
  embedding_size: 128 #64
  mask_depth: 3
  path_prob: 0.5
  num_attention_heads: 4
  num_gcn_layers: 2
  num_trm_layers: 2
  num_mask_cand: 50
  mask_steps: 10 # 100
  eps: 0.2
  attention_probs_dropout_prob: 0.3
  hidden_dropout_prob: 0.3

tune:
  enable: false # true # Whether to enable grid search to search for optimal hyperparameters
  hyperparameters: [lr]
  lr: [0.0001, 0.0003, 0.0005, 0.0007, 0.001]